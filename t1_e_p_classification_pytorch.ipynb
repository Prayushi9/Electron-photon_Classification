{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t1_e-p_classification_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDvQSGefYUeY"
      },
      "source": [
        "import numpy as np\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tL6wUrcZ9hA"
      },
      "source": [
        "hf = h5py.File('SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5', 'r')\n",
        "hf1 = h5py.File('SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5', 'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEQdEjZtad7-",
        "outputId": "9096e5f8-302f-4501-e2c7-2b9f7d3e4fd8"
      },
      "source": [
        "print(hf.keys())\n",
        "print(hf1.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<KeysViewHDF5 ['X', 'y']>\n",
            "<KeysViewHDF5 ['X', 'y']>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWr-puYMaj1a",
        "outputId": "5c118a68-0b11-4742-e3f9-1da6d98a12ef"
      },
      "source": [
        "#For electrons\n",
        "e_X = hf.get('X')\n",
        "print(e_X)\n",
        "e_y = hf.get('y')\n",
        "print(e_y)\n",
        "\n",
        "#for protons\n",
        "p_X = hf1.get('X')\n",
        "print(p_X)\n",
        "p_y = hf1.get('y')\n",
        "print(p_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<HDF5 dataset \"X\": shape (249000, 32, 32, 2), type \"<f4\">\n",
            "<HDF5 dataset \"y\": shape (249000,), type \"<f4\">\n",
            "<HDF5 dataset \"X\": shape (249000, 32, 32, 2), type \"<f4\">\n",
            "<HDF5 dataset \"y\": shape (249000,), type \"<f4\">\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV_MWsldauCZ",
        "outputId": "cdf8a02e-5043-4863-8b35-44dccd8a8b7f"
      },
      "source": [
        "e_X = np.array(e_X)\n",
        "print(e_X.shape)\n",
        "e_y = np.array(e_y)\n",
        "print(e_y.shape)\n",
        "\n",
        "p_X = np.array(p_X)\n",
        "print(p_X.shape)\n",
        "p_y = np.array(p_y)\n",
        "print(p_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(249000, 32, 32, 2)\n",
            "(249000,)\n",
            "(249000, 32, 32, 2)\n",
            "(249000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7MedJgHbYks"
      },
      "source": [
        "hf.close()\n",
        "hf1.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScwLpB16bfrg"
      },
      "source": [
        "e_train = []\n",
        "p_train = []\n",
        "e_val = []\n",
        "p_val = []\n",
        "e_test = []\n",
        "p_test = []\n",
        "for i in range(0,199200):\n",
        "  e_train.append(e_X[i])\n",
        "  p_train.append(p_X[i])\n",
        "\n",
        "for j in range(199200, 224100):\n",
        "  e_val.append(e_X[j])\n",
        "  p_val.append(p_X[j])\n",
        "\n",
        "for k in range(224100, 249000):\n",
        "  e_test.append(e_X[k])\n",
        "  p_test.append(p_X[k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnmJKmw3o5rL"
      },
      "source": [
        "X_train = np.concatenate([e_train, p_train])\n",
        "X_val = np.concatenate([e_val, p_val])\n",
        "X_test = np.concatenate([e_test, p_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUHJdo0zl-Ak",
        "outputId": "02db8325-3416-44cd-d343-15e5ca5fd99f"
      },
      "source": [
        "print((np.asarray(e_train)).shape)\n",
        "print((np.asarray(p_train)).shape)\n",
        "print((np.asarray(e_val)).shape)\n",
        "print((np.asarray(p_val)).shape)\n",
        "print((np.asarray(e_test)).shape)\n",
        "print((np.asarray(p_test)).shape)\n",
        "\n",
        "print((np.asarray(X_train)).shape)\n",
        "print((np.asarray(X_val)).shape)\n",
        "print((np.asarray(X_test)).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(199200, 32, 32, 2)\n",
            "(199200, 32, 32, 2)\n",
            "(24900, 32, 32, 2)\n",
            "(24900, 32, 32, 2)\n",
            "(24900, 32, 32, 2)\n",
            "(24900, 32, 32, 2)\n",
            "(398400, 32, 32, 2)\n",
            "(49800, 32, 32, 2)\n",
            "(49800, 32, 32, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WdFZkTIoKqg"
      },
      "source": [
        "ey_train = []\n",
        "py_train = []\n",
        "ey_val = []\n",
        "py_val = []\n",
        "ey_test = []\n",
        "py_test = []\n",
        "for i in range(0,199200):\n",
        "  ey_train.append(e_y[i])\n",
        "  py_train.append(p_y[i])\n",
        "\n",
        "for j in range(199200, 224100):\n",
        "  ey_val.append(e_y[j])\n",
        "  py_val.append(p_y[j])\n",
        "\n",
        "for k in range(224100, 249000):\n",
        "  ey_test.append(e_y[k])\n",
        "  py_test.append(p_y[k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HPqzv30q5em"
      },
      "source": [
        "Y_train = np.concatenate([ey_train, py_train])\n",
        "Y_val = np.concatenate([ey_val, py_val])\n",
        "Y_test = np.concatenate([ey_test, py_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9by7OgyUrVle",
        "outputId": "bf26693c-0aba-435f-c9ad-564f64a4d98b"
      },
      "source": [
        "print((np.asarray(ey_train)).shape)\n",
        "print((np.asarray(py_train)).shape)\n",
        "print((np.asarray(ey_val)).shape)\n",
        "print((np.asarray(py_val)).shape)\n",
        "print((np.asarray(ey_test)).shape)\n",
        "print((np.asarray(py_test)).shape)\n",
        "\n",
        "print((np.asarray(Y_train)).shape)\n",
        "print((np.asarray(Y_val)).shape)\n",
        "print((np.asarray(Y_test)).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(199200,)\n",
            "(199200,)\n",
            "(24900,)\n",
            "(24900,)\n",
            "(24900,)\n",
            "(24900,)\n",
            "(398400,)\n",
            "(49800,)\n",
            "(49800,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS9QWH0PGnFQ"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b9wtRhODV1i",
        "outputId": "c2256d39-19eb-470c-f06d-52f8459e52c2"
      },
      "source": [
        "input_size = 2048\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 2\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=2048, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=2, bias=True)\n",
            "  (5): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUSLv6gzmwFb",
        "outputId": "e30e00f2-58b9-4c11-d0a4-68cf37e13771"
      },
      "source": [
        "model = nn.Sequential(nn.Conv2d(2, 256, (3,3), 1, 1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.BatchNorm2d(256,momentum=0.8),\n",
        "                      nn.Conv2d(256, 256, (3,3), 1, 1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.BatchNorm2d(256, momentum=0.8),\n",
        "                      nn.Dropout(0.3),\n",
        "                      nn.Conv2d(256, 128, (3,3), 1, 1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.BatchNorm2d(128,momentum=0.8),\n",
        "                      nn.Conv2d(128, 64, (3,3), 1, 1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.BatchNorm2d(64, momentum=0.8),\n",
        "                      nn.Dropout(0.5),\n",
        "                      nn.Conv2d(64, 3, (3,3), 1, 1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Flatten(),\n",
        "                      nn.Linear(3,1),\n",
        "                      nn.Sigmoid())\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(2, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): BatchNorm2d(256, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
            "  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU()\n",
            "  (5): BatchNorm2d(256, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
            "  (6): Dropout(p=0.3, inplace=False)\n",
            "  (7): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU()\n",
            "  (9): BatchNorm2d(128, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
            "  (10): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): ReLU()\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
            "  (13): Dropout(p=0.5, inplace=False)\n",
            "  (14): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): ReLU()\n",
            "  (16): Flatten(start_dim=1, end_dim=-1)\n",
            "  (17): Linear(in_features=3, out_features=1, bias=True)\n",
            "  (18): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IntwkpXgKjrw",
        "outputId": "31986800-2edd-4493-b0a8-3a77f5a229eb"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=2048, out_features=128, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=64, out_features=2, bias=True)\n",
              "  (5): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2KAhziFWukA"
      },
      "source": [
        "y_train = []\n",
        "for i in range(199200):\n",
        "  y_train.append(1)\n",
        "\n",
        "for i in range(199200):\n",
        "  y_train.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yz1MRFCaMoV"
      },
      "source": [
        "y_train = np.asarray(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNYbqn3pcRVP",
        "outputId": "e4b78e88-5093-4dca-d66a-6a0ee2398362"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(398400, 32, 32, 2)\n",
            "(398400,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aZVQcJmUyBw"
      },
      "source": [
        "trainloader1 = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=False)\n",
        "trainloader2 = torch.utils.data.DataLoader(y_train, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5ud572WWnc5",
        "outputId": "de0a5b67-7c65-4ce9-ae8b-612017595368"
      },
      "source": [
        "print(trainloader1)\n",
        "print(trainloader2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f08b7b8ba50>\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7f08b7b840d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lw78ouAEpCL"
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "images = next(iter(trainloader1))\n",
        "labels = next(iter(trainloader2))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images) #log probabilities\n",
        "loss = criterion(logps, labels) #calculate the NLL loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5NsuHqrkGvb",
        "outputId": "c9a94324-cbfc-41f0-c8a1-b37ac4fa26e3"
      },
      "source": [
        "print(images[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoNvEigmkKOp",
        "outputId": "342c0f56-6069-40c6-8d6f-b77861cf6965"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe-LUVXTaoBQ",
        "outputId": "62c0170a-12ca-412b-fd5e-5f6ff0556a08"
      },
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "loss.backward()\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH_k_ZyVa-ks",
        "outputId": "89257979-84a9-4da5-fb6e-5839946e63a8"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "time0 = time()\n",
        "epochs = 150\n",
        "num_batches = 1\n",
        "correct_count, all_count = 0, 0\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    # for (images, labels) in (trainloader1, trainloader2):\n",
        "    for idx in range(num_batches):\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        # images = images.view(images.shape[0], -1)\n",
        "        # correct = 0\n",
        "        # total = 0\n",
        "        images = next(iter(trainloader1))\n",
        "        labels = next(iter(trainloader2))\n",
        "        # print(labels)\n",
        "        # print(images1.shape)\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images)\n",
        "        # print(output)\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        \n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {} \".format(e, running_loss/len(trainloader2)))\n",
        "# print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - Training loss: 1.175616938905065e-06 \n",
            "Epoch 1 - Training loss: 1.1722988123635212e-06 \n",
            "Epoch 2 - Training loss: 1.166053340736642e-06 \n",
            "Epoch 3 - Training loss: 1.157260907582011e-06 \n",
            "Epoch 4 - Training loss: 1.146136502544564e-06 \n",
            "Epoch 5 - Training loss: 1.13303754403888e-06 \n",
            "Epoch 6 - Training loss: 1.1181509698251165e-06 \n",
            "Epoch 7 - Training loss: 1.1016997736859992e-06 \n",
            "Epoch 8 - Training loss: 1.083924004950198e-06 \n",
            "Epoch 9 - Training loss: 1.0650903435356645e-06 \n",
            "Epoch 10 - Training loss: 1.0452670116261785e-06 \n",
            "Epoch 11 - Training loss: 1.024611099776494e-06 \n",
            "Epoch 12 - Training loss: 1.0033537555171783e-06 \n",
            "Epoch 13 - Training loss: 9.816279073795641e-07 \n",
            "Epoch 14 - Training loss: 9.595316247528336e-07 \n",
            "Epoch 15 - Training loss: 9.371353739715485e-07 \n",
            "Epoch 16 - Training loss: 9.145388701354644e-07 \n",
            "Epoch 17 - Training loss: 8.918493836519709e-07 \n",
            "Epoch 18 - Training loss: 8.692955186807487e-07 \n",
            "Epoch 19 - Training loss: 8.46831644155893e-07 \n",
            "Epoch 20 - Training loss: 8.246875611175016e-07 \n",
            "Epoch 21 - Training loss: 8.028002089285947e-07 \n",
            "Epoch 22 - Training loss: 7.811806587330309e-07 \n",
            "Epoch 23 - Training loss: 7.597681688496387e-07 \n",
            "Epoch 24 - Training loss: 7.386266975757109e-07 \n",
            "Epoch 25 - Training loss: 7.177827258904775e-07 \n",
            "Epoch 26 - Training loss: 6.973011845565704e-07 \n",
            "Epoch 27 - Training loss: 6.771842429197457e-07 \n",
            "Epoch 28 - Training loss: 6.573927031463409e-07 \n",
            "Epoch 29 - Training loss: 6.379594046428022e-07 \n",
            "Epoch 30 - Training loss: 6.189052928164302e-07 \n",
            "Epoch 31 - Training loss: 6.002138731589758e-07 \n",
            "Epoch 32 - Training loss: 5.818998074555493e-07 \n",
            "Epoch 33 - Training loss: 5.640186384380103e-07 \n",
            "Epoch 34 - Training loss: 5.465499817367538e-07 \n",
            "Epoch 35 - Training loss: 5.294704981836449e-07 \n",
            "Epoch 36 - Training loss: 5.127936152808637e-07 \n",
            "Epoch 37 - Training loss: 4.965532571077346e-07 \n",
            "Epoch 38 - Training loss: 4.807519670351442e-07 \n",
            "Epoch 39 - Training loss: 4.6538110508258083e-07 \n",
            "Epoch 40 - Training loss: 4.5042496219456917e-07 \n",
            "Epoch 41 - Training loss: 4.358910562762295e-07 \n",
            "Epoch 42 - Training loss: 4.217483432417414e-07 \n",
            "Epoch 43 - Training loss: 4.080064729394683e-07 \n",
            "Epoch 44 - Training loss: 3.946860541540935e-07 \n",
            "Epoch 45 - Training loss: 3.8174433581321593e-07 \n",
            "Epoch 46 - Training loss: 3.691822155771485e-07 \n",
            "Epoch 47 - Training loss: 3.569926991759534e-07 \n",
            "Epoch 48 - Training loss: 3.4517429050910906e-07 \n",
            "Epoch 49 - Training loss: 3.33726503343946e-07 \n",
            "Epoch 50 - Training loss: 3.2263598498331015e-07 \n",
            "Epoch 51 - Training loss: 3.118955541446985e-07 \n",
            "Epoch 52 - Training loss: 3.0150571576203687e-07 \n",
            "Epoch 53 - Training loss: 2.9146914411500756e-07 \n",
            "Epoch 54 - Training loss: 2.8176272445055375e-07 \n",
            "Epoch 55 - Training loss: 2.723705981031479e-07 \n",
            "Epoch 56 - Training loss: 2.632923723464031e-07 \n",
            "Epoch 57 - Training loss: 2.545386507927653e-07 \n",
            "Epoch 58 - Training loss: 2.460906947832031e-07 \n",
            "Epoch 59 - Training loss: 2.3793702174621413e-07 \n",
            "Epoch 60 - Training loss: 2.3006992676411289e-07 \n",
            "Epoch 61 - Training loss: 2.2248428569261328e-07 \n",
            "Epoch 62 - Training loss: 2.1517362789696e-07 \n",
            "Epoch 63 - Training loss: 2.0812615288428992e-07 \n",
            "Epoch 64 - Training loss: 2.0133720404172998e-07 \n",
            "Epoch 65 - Training loss: 1.9480229306771573e-07 \n",
            "Epoch 66 - Training loss: 1.885148745224658e-07 \n",
            "Epoch 67 - Training loss: 1.824618201239042e-07 \n",
            "Epoch 68 - Training loss: 1.7662785094545547e-07 \n",
            "Epoch 69 - Training loss: 1.7100475713550805e-07 \n",
            "Epoch 70 - Training loss: 1.656032171115339e-07 \n",
            "Epoch 71 - Training loss: 1.60414029855326e-07 \n",
            "Epoch 72 - Training loss: 1.5541436113267538e-07 \n",
            "Epoch 73 - Training loss: 1.506078950911162e-07 \n",
            "Epoch 74 - Training loss: 1.4598051228197702e-07 \n",
            "Epoch 75 - Training loss: 1.415287062196607e-07 \n",
            "Epoch 76 - Training loss: 1.3724860574406792e-07 \n",
            "Epoch 77 - Training loss: 1.3312975685280488e-07 \n",
            "Epoch 78 - Training loss: 1.2917069149723495e-07 \n",
            "Epoch 79 - Training loss: 1.2536278839810306e-07 \n",
            "Epoch 80 - Training loss: 1.2169789380756726e-07 \n",
            "Epoch 81 - Training loss: 1.1817438071631044e-07 \n",
            "Epoch 82 - Training loss: 1.147851239455991e-07 \n",
            "Epoch 83 - Training loss: 1.1152551363570144e-07 \n",
            "Epoch 84 - Training loss: 1.083952225146284e-07 \n",
            "Epoch 85 - Training loss: 1.0538324489291892e-07 \n",
            "Epoch 86 - Training loss: 1.0248427896435002e-07 \n",
            "Epoch 87 - Training loss: 9.969497720400492e-08 \n",
            "Epoch 88 - Training loss: 9.700967313115855e-08 \n",
            "Epoch 89 - Training loss: 9.442580467366789e-08 \n",
            "Epoch 90 - Training loss: 9.193763989641006e-08 \n",
            "Epoch 91 - Training loss: 8.954141984682485e-08 \n",
            "Epoch 92 - Training loss: 8.723337622172383e-08 \n",
            "Epoch 93 - Training loss: 8.500998383425325e-08 \n",
            "Epoch 94 - Training loss: 8.286828788588325e-08 \n",
            "Epoch 95 - Training loss: 8.080444526839926e-08 \n",
            "Epoch 96 - Training loss: 7.881458482170201e-08 \n",
            "Epoch 97 - Training loss: 7.689685512139615e-08 \n",
            "Epoch 98 - Training loss: 7.504677721654554e-08 \n",
            "Epoch 99 - Training loss: 7.326217708607994e-08 \n",
            "Epoch 100 - Training loss: 7.154028694403459e-08 \n",
            "Epoch 101 - Training loss: 6.98789093927686e-08 \n",
            "Epoch 102 - Training loss: 6.827496340027056e-08 \n",
            "Epoch 103 - Training loss: 6.67256391027486e-08 \n",
            "Epoch 104 - Training loss: 6.52310487077418e-08 \n",
            "Epoch 105 - Training loss: 6.37871948216694e-08 \n",
            "Epoch 106 - Training loss: 6.23912582301112e-08 \n",
            "Epoch 107 - Training loss: 6.104185504008488e-08 \n",
            "Epoch 108 - Training loss: 5.973730213850378e-08 \n",
            "Epoch 109 - Training loss: 5.8474756934377086e-08 \n",
            "Epoch 110 - Training loss: 5.72528121581518e-08 \n",
            "Epoch 111 - Training loss: 5.607094417464542e-08 \n",
            "Epoch 112 - Training loss: 5.4927455844828884e-08 \n",
            "Epoch 113 - Training loss: 5.382035080956886e-08 \n",
            "Epoch 114 - Training loss: 5.2747917903893925e-08 \n",
            "Epoch 115 - Training loss: 5.1708436612204374e-08 \n",
            "Epoch 116 - Training loss: 5.070195836295564e-08 \n",
            "Epoch 117 - Training loss: 4.9725879006177546e-08 \n",
            "Epoch 118 - Training loss: 4.877964217948866e-08 \n",
            "Epoch 119 - Training loss: 4.786152736728929e-08 \n",
            "Epoch 120 - Training loss: 4.697038911761768e-08 \n",
            "Epoch 121 - Training loss: 4.6105960937568464e-08 \n",
            "Epoch 122 - Training loss: 4.5266802830389703e-08 \n",
            "Epoch 123 - Training loss: 4.445205453828157e-08 \n",
            "Epoch 124 - Training loss: 4.366115969886263e-08 \n",
            "Epoch 125 - Training loss: 4.289324870370478e-08 \n",
            "Epoch 126 - Training loss: 4.214629246647578e-08 \n",
            "Epoch 127 - Training loss: 4.142030033780389e-08 \n",
            "Epoch 128 - Training loss: 4.071412219041323e-08 \n",
            "Epoch 129 - Training loss: 4.002776737493205e-08 \n",
            "Epoch 130 - Training loss: 3.936037563356051e-08 \n",
            "Epoch 131 - Training loss: 3.871077346245208e-08 \n",
            "Epoch 132 - Training loss: 3.807839514859709e-08 \n",
            "Epoch 133 - Training loss: 3.7462660953043455e-08 \n",
            "Epoch 134 - Training loss: 3.686358022641944e-08 \n",
            "Epoch 135 - Training loss: 3.627969427071661e-08 \n",
            "Epoch 136 - Training loss: 3.5711012436563235e-08 \n",
            "Epoch 137 - Training loss: 3.515724952979739e-08 \n",
            "Epoch 138 - Training loss: 3.461723438422962e-08 \n",
            "Epoch 139 - Training loss: 3.409068180569803e-08 \n",
            "Epoch 140 - Training loss: 3.357730426238364e-08 \n",
            "Epoch 141 - Training loss: 3.307622513288714e-08 \n",
            "Epoch 142 - Training loss: 3.2587748312626976e-08 \n",
            "Epoch 143 - Training loss: 3.2111581594470035e-08 \n",
            "Epoch 144 - Training loss: 3.1646551474569794e-08 \n",
            "Epoch 145 - Training loss: 3.119237275876434e-08 \n",
            "Epoch 146 - Training loss: 3.074904544705368e-08 \n",
            "Epoch 147 - Training loss: 3.031598746282868e-08 \n",
            "Epoch 148 - Training loss: 2.989320581906052e-08 \n",
            "Epoch 149 - Training loss: 2.9479814543721666e-08 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfAvccVULkGS"
      },
      "source": [
        "y_val = []\n",
        "for i in range(24900):\n",
        "  y_val.append(1)\n",
        "\n",
        "for i in range(24900):\n",
        "  y_val.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk--xNYBLwtN"
      },
      "source": [
        "y_val = np.asarray(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skF2MLI2LwwD",
        "outputId": "5a67cf73-6456-4bb2-eb9b-34200c36e112"
      },
      "source": [
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49800, 32, 32, 2)\n",
            "(49800,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCuruqxtbGgy"
      },
      "source": [
        "valloader1 = torch.utils.data.DataLoader(X_val, batch_size=1, shuffle=False)\n",
        "valloader2 = torch.utils.data.DataLoader(y_val, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxJEgIFFNlHn",
        "outputId": "fab5075b-d203-4a2d-edf8-4576ea0f9528"
      },
      "source": [
        "correct_count, all_count = 0, 0\n",
        "# for images,labels in valloader:\n",
        "for idx in range(49800):\n",
        "  images = next(iter(valloader1))\n",
        "  labels = next(iter(valloader2))\n",
        "  for i in range(len(labels)):\n",
        "    img = images[i].view(1, 2048)\n",
        "    # Turn off gradients to speed up this part\n",
        "    with torch.no_grad():\n",
        "        logps = model(img)\n",
        "\n",
        "    # Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Of Images Tested = 49800\n",
            "\n",
            "Model Accuracy = 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMEgMr5jPG8J",
        "outputId": "3980d48d-fb82-4cdb-85ea-a0478c427523"
      },
      "source": [
        "print(Y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. ... 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAlkIeeqTQOt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}